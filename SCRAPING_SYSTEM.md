# ğŸ•·ï¸ Sistema de Scraping Escalable para Miles de Jugadores

## ğŸ“‹ Resumen

Se ha implementado un sistema robusto y escalable de scraping de datos de Transfermarkt que puede procesar **miles de jugadores sin problemas de timeout**.

## âœ… Mejoras Implementadas

### 1. **Procesamiento por Lotes (Batch Processing)**
- Divide el trabajo en lotes de 10 jugadores
- Cada lote se procesa en una request HTTP separada
- Tiempo mÃ¡ximo por batch: 5 minutos (configurado con `maxDuration = 300`)
- Sin riesgo de timeouts en Vercel

### 2. **Persistencia de Progreso**
- Nueva tabla `ScrapingJob` en la base de datos
- Guarda el estado del trabajo: pending, running, paused, completed, failed
- Tracking de progreso: total, procesados, exitosos, errores
- Se puede reanudar desde donde se detuvo si se interrumpe

### 3. **Procesamiento AutomÃ¡tico**
- El frontend hace polling cada 2 segundos
- Procesa automÃ¡ticamente el siguiente batch hasta completar todos los jugadores
- No requiere intervenciÃ³n manual

### 4. **Control Total**
- **Iniciar**: Crea un nuevo trabajo de scraping
- **Pausar**: Detiene temporalmente el procesamiento
- **Reanudar**: ContinÃºa desde donde se pausÃ³
- **Cancelar**: Termina permanentemente el trabajo
- **Reset**: Limpia la interfaz para empezar de nuevo

### 5. **Monitoreo en Tiempo Real**
- Dashboard con mÃ©tricas en vivo:
  - Total de jugadores
  - Jugadores procesados
  - Exitosos
  - Errores
  - Barra de progreso (%)
- Logs detallados con timestamps
- Estado visible del job

## ğŸ—‚ï¸ Estructura de Archivos

### Base de Datos
```
prisma/schema.prisma
â””â”€â”€ model ScrapingJob
    â”œâ”€â”€ id: String (ID Ãºnico del job)
    â”œâ”€â”€ status: String (pending, running, paused, completed, failed)
    â”œâ”€â”€ totalPlayers: Int (total de jugadores a procesar)
    â”œâ”€â”€ processedCount: Int (jugadores procesados hasta ahora)
    â”œâ”€â”€ successCount: Int (jugadores exitosos)
    â”œâ”€â”€ errorCount: Int (jugadores con error)
    â”œâ”€â”€ currentBatch: Int (nÃºmero del batch actual)
    â”œâ”€â”€ batchSize: Int (tamaÃ±o del batch, default: 10)
    â””â”€â”€ timestamps (startedAt, completedAt, lastProcessedAt)
```

### API Routes
```
src/app/api/admin/scraping/
â”œâ”€â”€ start/route.ts       - POST: Iniciar nuevo job
â”œâ”€â”€ process/route.ts     - POST: Procesar siguiente batch
â”œâ”€â”€ status/route.ts      - GET: Obtener estado del job
â”œâ”€â”€ pause/route.ts       - POST: Pausar job activo
â””â”€â”€ cancel/route.ts      - POST: Cancelar job activo
```

### Frontend
```
src/app/admin/scraping/page.tsx - Dashboard interactivo
```

## ğŸ”§ API Endpoints

### 1. Iniciar Scraping
```bash
POST /api/admin/scraping/start
```
**Respuesta:**
```json
{
  "success": true,
  "message": "Job de scraping creado exitosamente",
  "job": {
    "id": "clxxx...",
    "status": "pending",
    "totalPlayers": 1500,
    "batchSize": 10
  }
}
```

### 2. Procesar Batch
```bash
POST /api/admin/scraping/process
```
**Respuesta:**
```json
{
  "success": true,
  "completed": false,
  "message": "Batch procesado: 9 exitosos, 1 errores",
  "job": {
    "id": "clxxx...",
    "status": "running",
    "totalPlayers": 1500,
    "processedCount": 10,
    "successCount": 9,
    "errorCount": 1,
    "currentBatch": 1,
    "progress": 1
  },
  "results": [
    {
      "playerId": "xxx",
      "playerName": "Lionel Messi",
      "url": "https://www.transfermarkt.es/...",
      "success": true,
      "fieldsUpdated": ["team_name", "position_player", "height", ...]
    },
    ...
  ]
}
```

### 3. Obtener Estado
```bash
GET /api/admin/scraping/status
```
**Respuesta:**
```json
{
  "exists": true,
  "job": {
    "id": "clxxx...",
    "status": "running",
    "totalPlayers": 1500,
    "processedCount": 150,
    "successCount": 145,
    "errorCount": 5,
    "progress": 10,
    "currentBatch": 15,
    ...
  }
}
```

### 4. Pausar/Cancelar
```bash
POST /api/admin/scraping/pause   # Pausar
POST /api/admin/scraping/cancel  # Cancelar
```

## ğŸ“Š Campos ExtraÃ­dos (14 campos)

El sistema extrae los siguientes campos de cada jugador desde Transfermarkt:

1. **advisor** - Nombre del agente/asesor
2. **url_trfm_advisor** - URL del perfil del asesor
3. **date_of_birth** - Fecha de nacimiento
4. **team_name** - Equipo actual
5. **team_loan_from** - Equipo del que estÃ¡ cedido
6. **position_player** - PosiciÃ³n del jugador
7. **foot** - Pie dominante
8. **height** - Altura en cm
9. **nationality_1** - Nacionalidad principal
10. **nationality_2** - Nacionalidad secundaria
11. **national_tier** - Nivel de selecciÃ³n nacional
12. **agency** - Agencia representante
13. **contract_end** - Fecha de fin de contrato
14. **player_trfm_value** - Valor de mercado en â‚¬

## âš™ï¸ ConfiguraciÃ³n

### TamaÃ±o de Batch
Por defecto: **10 jugadores por batch**

Puedes ajustarlo en `src/app/api/admin/scraping/start/route.ts`:
```typescript
batchSize: 10  // Cambiar aquÃ­
```

### Pausas Entre Requests
- **Entre jugadores**: 3 segundos (evita rate limiting de Transfermarkt)
- **Entre batches**: AutomÃ¡tico (2 segundos polling del frontend)

### Timeout por Batch
Configurado en `src/app/api/admin/scraping/process/route.ts`:
```typescript
export const maxDuration = 300  // 5 minutos (mÃ¡ximo en Vercel)
```

## ğŸš€ Uso

### 1. Acceder a la interfaz
```
https://tu-dominio.com/admin/scraping
```

### 2. Iniciar Scraping
1. Haz clic en "Iniciar Scraping"
2. El sistema crearÃ¡ un nuevo job
3. El procesamiento comenzarÃ¡ automÃ¡ticamente

### 3. Monitorear Progreso
- Observa las mÃ©tricas en tiempo real
- Lee los logs para ver detalles de cada jugador
- La barra de progreso muestra el % completado

### 4. Control del Proceso
- **Pausar**: Detiene temporalmente (puedes cerrar la pÃ¡gina)
- **Reanudar**: ContinÃºa desde donde se pausÃ³
- **Cancelar**: Termina permanentemente el job
- **Reset**: Limpia la interfaz

## ğŸ¯ Ventajas del Nuevo Sistema

### âœ… Escalabilidad
- Puede procesar **miles o millones** de jugadores
- No hay lÃ­mite de tiempo total
- Cada batch es independiente

### âœ… Resiliencia
- Si falla un batch, continÃºa con el siguiente
- El progreso se guarda en la base de datos
- Puedes cerrar el navegador y reanudar despuÃ©s

### âœ… Control
- Pausar/reanudar en cualquier momento
- Cancelar si es necesario
- Monitoreo en tiempo real

### âœ… Rendimiento
- Procesamiento paralelo dentro de cada batch
- Pausas configurables para evitar bloqueos
- Rate limiting inteligente

## ğŸ“ˆ Ejemplo de Uso Real

### Escenario: 5,000 jugadores

- **Batch size**: 10 jugadores
- **Total batches**: 500 batches
- **Tiempo por jugador**: ~5 segundos (con pausa de 3 seg)
- **Tiempo por batch**: ~50 segundos
- **Tiempo total estimado**: ~7 horas

El sistema procesarÃ¡ automÃ¡ticamente todos los batches sin intervenciÃ³n manual.

## ğŸ” Troubleshooting

### Job se queda en "running"
1. Verifica los logs en la interfaz
2. Revisa los logs del servidor
3. Usa el botÃ³n "Cancelar" y crea un nuevo job

### Rate limiting de Transfermarkt
- Aumenta la pausa entre jugadores en `process/route.ts`
- Reduce el tamaÃ±o del batch

### Errores frecuentes en ciertos jugadores
- Verifica la estructura HTML de Transfermarkt
- Actualiza los regex de scraping si cambiÃ³ el HTML
- Los errores no detienen el proceso completo

## ğŸ” Seguridad

- Solo usuarios con rol **admin** pueden ejecutar scraping
- AutenticaciÃ³n mediante Clerk
- ValidaciÃ³n en todos los endpoints
- No se exponen URLs o datos sensibles

## ğŸ“ Logs y AuditorÃ­a

El sistema registra:
- Fecha/hora de inicio y fin
- Total de jugadores procesados
- Jugadores exitosos vs errores
- Detalles de cada jugador procesado
- Errores especÃ­ficos por jugador

Todos los logs estÃ¡n disponibles en:
1. Interfaz web (tiempo real)
2. Console del servidor
3. Base de datos (tabla `ScrapingJob`)

## ğŸ‰ ConclusiÃ³n

El nuevo sistema estÃ¡ **completamente preparado para scrapear miles de jugadores** de manera eficiente, robusta y sin timeouts. âœ…
